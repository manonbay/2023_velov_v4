{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import json\n",
    "import requests\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from calendar import monthrange\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 19s\n",
      "Wall time: 9min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "def save_data_pkl(df) -> None : \n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    nom_fichier = f'dump{year}_{month}_15min'\n",
    "    with open(nom_fichier + \".pkl\", 'wb') as f: # nom du fichier à créer\n",
    "        pickle.dump(df, f)\n",
    "\n",
    "def clean_df(df) -> pd.DataFrame: \n",
    "    df=df[[\"horodate\",\n",
    "                \"number\", \n",
    "                \"status\",\n",
    "                'total_stands.availabilities.bikes', \n",
    "                'total_stands.availabilities.electricalBikes',\n",
    "                'total_stands.availabilities.stands',\n",
    "                'total_stands.capacity']] \n",
    "    df.rename(columns={'total_stands.availabilities.bikes' : 'availabilities.all.types',\n",
    "            'total_stands.availabilities.electricalBikes' : 'availabilities.electricalBikes',\n",
    "            'total_stands.availabilities.stands' : \"availabilities.stands\", \n",
    "            'total_stands.capacity' :\"capacity\"}, inplace=True)\n",
    "    df.sort_values([\"number\", \"horodate\"], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df[\"horodate\"] = pd.to_datetime(df[\"horodate\"], cache=True)\n",
    "    df.set_index(\"horodate\", inplace=True)\n",
    "    df = df.groupby(\"number\").resample('15T').bfill()\n",
    "    df = df.droplevel(level=0).reset_index()\n",
    "    return df\n",
    "\n",
    "def load_monthly_data_from_API(year, month) -> pd.DataFrame:\n",
    "    link_part1 = \"https://download.data.grandlyon.com/ws/timeseries/jcd_jcdecaux.historiquevelov/all.json?horodate__gte=\"\n",
    "    link_part2 = \"&maxfeatures=600000\"\n",
    "    last_day_of_month = monthrange(year,month)[1]\n",
    "    for day in range (1, monthrange(year,month)[1]+1) :\n",
    "        if day != monthrange(year,month)[1] : \n",
    "            URL = f'{link_part1}{year}-{month}-{day}-&horodate__lte={year}-{month}-{day+1}{link_part2}'\n",
    "        else :\n",
    "            URL = f'{link_part1}{year}-{month}-{day}-&horodate__lte={year}-{(month+1)}-1{link_part2}'\n",
    "        \n",
    "        persistent_connexion = requests.Session()   \n",
    "        response = persistent_connexion.get(URL)\n",
    "        \n",
    "        try : \n",
    "            response.raise_for_status() # à tester, retourne une erreur si response !=200\n",
    "            data_endpoint = json.loads(response.text)\n",
    "            historique_journalier = pd.json_normalize(data_endpoint, record_path=\"values\")\n",
    "            historique_journalier = clean_df(historique_journalier)\n",
    "        \n",
    "            if day==1 : #initialisation du df # modifier pour si date 1==erreur\n",
    "                historique = historique_journalier\n",
    "            else : \n",
    "                historique = pd.concat([historique,historique_journalier])\n",
    "            del(historique_journalier)\n",
    "        except KeyError as e : \n",
    "            print(f'{year}-{month}-{day} : KeyError', e)\n",
    "        except json.decoder.JSONDecodeError as e :    \n",
    "            print(f'{year}-{month}-{day} :JSONDecodeError', e)\n",
    "        \n",
    "\n",
    "    return historique    \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    year=2023\n",
    "    month=11\n",
    "    dataframe_month = load_monthly_data_from_API(year=year, month=month)\n",
    "    save_data_pkl(dataframe_month)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geocoding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
